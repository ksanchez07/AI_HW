{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcRVUziqz7hB"
      },
      "source": [
        "# Assignment 4\n",
        "\n",
        "This is an basecode for assignment 4 of Artificial Intelligence class (CSCE-4613), Spring 2025\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih72pU-4h0BT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NBXrZkzlhS"
      },
      "source": [
        "## Binary Network\n",
        "\n",
        "## Define a binary network class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXkjOLlQh4B0"
      },
      "outputs": [],
      "source": [
        "class BinaryNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x has the size of (batch size x 2)\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_O-MPTzxo1"
      },
      "source": [
        "### Define data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU9RPLbqi-tL"
      },
      "outputs": [],
      "source": [
        "def generate_data(operator = \"AND\"):\n",
        "  assert operator in [\"AND\", \"OR\", \"XOR\", \"NOR\"], \"%s operator is not valid\" % operator\n",
        "  data = []\n",
        "  label = []\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      data.append([i, j])\n",
        "      if operator == \"AND\":\n",
        "        label.append(i & j)\n",
        "      elif operator == \"OR\":\n",
        "        label.append(i | j)\n",
        "      elif operator == \"XOR\":\n",
        "        label.append(i ^ j)\n",
        "      else:\n",
        "        label.append(not (i | j))\n",
        "  data = torch.as_tensor(data, dtype = torch.float32)\n",
        "  label = torch.as_tensor(label, dtype = torch.float32)\n",
        "  return data, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rKa_T9az3G6"
      },
      "source": [
        "### Define the training framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbF7qM7LkqFc"
      },
      "outputs": [],
      "source": [
        "model = BinaryNetwork()\n",
        "model.train()\n",
        "print(model)\n",
        "operator = \"XOR\"\n",
        "inputs, labels = generate_data(operator = operator)\n",
        "\n",
        "n_iters = 1000\n",
        "learning_rate = 0.1\n",
        "\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "\n",
        "\n",
        "for i in range(1, n_iters + 1):\n",
        "\n",
        "  # WRITE YOUR CODE TO COMPUTE OUTPUTS, LOSS, ACCURACY, AND OPTIMIZE MODEL\n",
        "  # outptus = ???\n",
        "  # loss = ???\n",
        "  # accuracy = ???\n",
        "  # optimize the model\n",
        "  loss = 0.0\n",
        "  accuracy = 0.0\n",
        "\n",
        "  if i % 5 == 0:\n",
        "    print(\"[%d/%d]. Loss: %0.4f. Accuracy: %0.2f\" % (i, n_iters, loss, accuracy))\n",
        "\n",
        "model.eval()\n",
        "# WRITE YOUR CODE TO CALCULATE THE FINAL ACCURACY\n",
        "# accuracy = ???\n",
        "accuracy = 0.0\n",
        "print(\"Final Accuracy: %0.2f\" % (accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), \"%s_Network.pth\" % operator)\n",
        "  # model.load_state_dict(torch.load(\"%s_Network.pth\" % operator)) # Load model in the next time you use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE5YlJ_I3NYg"
      },
      "source": [
        "## Digit Classification\n",
        "\n",
        "### Define Digit Classification Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI2eUjVG0Ssz"
      },
      "outputs": [],
      "source": [
        "class DigitNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DigitNetwork, self).__init__()\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x has the size of (batch size x 1 x height x height)\n",
        "    # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JTjiev9CK4K"
      },
      "source": [
        "### Define Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUnVAlP85SGs"
      },
      "outputs": [],
      "source": [
        "def create_data_generator(batch_size = 32, root = \"data\"):\n",
        "  train_dataset = torchvision.datasets.MNIST(root = root,\n",
        "                                             train = True,\n",
        "                                             transform = torchvision.transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "  test_dataset = torchvision.datasets.MNIST(root = root,\n",
        "                                             train = False,\n",
        "                                             transform = torchvision.transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = False)\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AZSB2N3CTFd"
      },
      "source": [
        "### Define the training framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDmnwaOT66-S"
      },
      "outputs": [],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = DigitNetwork()\n",
        "print(model)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "n_epochs = 1\n",
        "learning_rate = 0.1\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    # WRITE YOUR CODE TO COMPUTE OUTPUTS, LOSS, ACCURACY, AND OPTIMIZE MODEL\n",
        "    # outptus = ???\n",
        "    # loss = ???\n",
        "    # accuracy = ???\n",
        "    # optimize the model\n",
        "    loss = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"Epoch [%d/%d]. Iter [%d/%d]. Loss: %0.2f. Accuracy: %0.2f\" % (epoch, n_epochs, idx + 1, len(train_loader), loss, accuracy))\n",
        "\n",
        "torch.save(model.state_dict(), \"MNIST_Network.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_nZTwv1CbGl"
      },
      "source": [
        "### Define the evaluation framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLbEk4QZ6_4K"
      },
      "outputs": [],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 1\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = DigitNetwork()\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "model.eval()\n",
        "model.load_state_dict(torch.load(\"MNIST_Network.pth\"))\n",
        "\n",
        "total_accuracy = 0.0\n",
        "for idx, (images, labels) in enumerate(test_loader):\n",
        "  # WRITE YOUR CODE TO COMPUTE ACCURACY\n",
        "  # accuracy = ???\n",
        "  accuracy = 0.0\n",
        "\n",
        "  total_accuracy += accuracy\n",
        "\n",
        "  if idx % 2000 == 0:\n",
        "    print(\"Iter [%d/%d]. Accuracy: %0.2f\" % (idx + 1, len(test_loader), accuracy))\n",
        "\n",
        "print(\"Final Accuracy: %0.2f\" % (total_accuracy / len(test_loader)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmpi69Q-bzDj"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "### ReLU Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWoO_sciAqDa"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#pytorch-defining-new-autograd-functions\n",
        "class MyReLU(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sJY_Gnvb7wP"
      },
      "source": [
        "#### Sigmoid Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj3ac-EVRvMz"
      },
      "outputs": [],
      "source": [
        "class MySigmoid(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        # input is a N x C tensor, N is the batch size, C is the dimension of input\n",
        "        ctx.save_for_backward(input)\n",
        "        # YOUR CODE HERE\n",
        "        # return output of sigmoid function\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        # YOUR CODE HERE\n",
        "        # return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgjRo-W1b_CD"
      },
      "source": [
        "#### Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyxyWGNaXvG_"
      },
      "outputs": [],
      "source": [
        "class MyLinearFunction(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, weights, bias):\n",
        "        # input is a N x C tensor, N is the batch size, C is the dimension of input\n",
        "        # weights is a C x D tensor, C and D are the dimension out input and ouput\n",
        "        # bias is D tensor\n",
        "        ctx.save_for_backward(input, weights, bias)\n",
        "        # YOUR CODE HERE\n",
        "        # return output of linear function\n",
        "        return torch.matmul(input, weights) + bias\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, weights, bias = ctx.saved_tensors\n",
        "        # YOUR CODE HERE\n",
        "        # return grad_input, grad_weights, grad_bias\n",
        "\n",
        "class MyLinearLayer(nn.Module):\n",
        "  # You don't modify this layer\n",
        "  def __init__(self, in_features = 2, out_features = 4):\n",
        "    super(MyLinearLayer, self).__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(in_features, out_features))\n",
        "    self.bias = nn.Parameter(torch.zeros(out_features))\n",
        "    self.linear_fn = MyLinearFunction.apply\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.linear_fn(input, self.weights, self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUjXs20ecGBG"
      },
      "source": [
        "#### Testing Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95fQHamjZMX1"
      },
      "outputs": [],
      "source": [
        "class MyLinearNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyLinearNetwork, self).__init__()\n",
        "    self.linear_1 = MyLinearLayer(28 * 28, 128)\n",
        "    self.sigmoid_fn = MySigmoid.apply\n",
        "    self.linear_2 = MyLinearLayer(128, 10)\n",
        "    self.softmax_fn = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    size = x.size()\n",
        "    x = x.reshape(size[0], -1) # Flatten images\n",
        "    x = self.linear_1(x)\n",
        "    x = self.sigmoid_fn(x)\n",
        "    x = self.linear_2(x)\n",
        "    if self.training == False:\n",
        "      x = self.softmax_fn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-PND4sBcwgM"
      },
      "outputs": [],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "batch_size = 32\n",
        "train_loader, test_loader = create_data_generator(batch_size)\n",
        "model = MyLinearNetwork()\n",
        "print(model)\n",
        "if cuda:\n",
        "  model.cuda()\n",
        "n_epochs = 3\n",
        "learning_rate = 0.1\n",
        "optim = torch.optim.SGD(params = model.parameters(), lr = learning_rate, momentum=0.9)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  for idx, (images, labels) in enumerate(train_loader):\n",
        "    # WRITE YOUR CODE TO COMPUTE OUTPUTS, LOSS, ACCURACY, AND OPTIMIZE MODEL\n",
        "    # outptus = ???\n",
        "    # loss = ???\n",
        "    # accuracy = ???\n",
        "    # optimize the model\n",
        "    loss = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\"Epoch [%d/%d]. Iter [%d/%d]. Loss: %0.2f. Accuracy: %0.2f\" % (epoch, n_epochs, idx + 1, len(train_loader), loss, accuracy))\n",
        "\n",
        "total_accuracy = 0.0\n",
        "model.eval()\n",
        "for idx, (images, labels) in enumerate(test_loader):\n",
        "  # WRITE YOUR CODE TO COMPUTE ACCURACY\n",
        "  # accuracy = ???\n",
        "  accuracy = 0.0\n",
        "\n",
        "  total_accuracy += accuracy\n",
        "\n",
        "  if idx % 2000 == 0:\n",
        "    print(\"Iter [%d/%d]. Accuracy: %0.2f\" % (idx + 1, len(test_loader), accuracy))\n",
        "\n",
        "print(\"Final Accuracy: %0.2f\" % (total_accuracy / len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP5Vc_zriFmK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
